








!pip install rdkit-pypi
!git clone https://github.com/ARIM-Academy/Advanced_Tutorial_4.git

%cd Advanced_Tutorial_4





#データ構造化ライブラリ
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt 

#記述子ライブラリ
from rdkit import Chem
from rdkit.Chem import AllChem
from rdkit.Chem.AllChem import GetHashedMorganFingerprint

#機械学習
from sklearn.model_selection import train_test_split

from sklearn.linear_model import LinearRegression
from sklearn.cross_decomposition import PLSRegression
from sklearn.ensemble import RandomForestRegressor

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

from warnings import filterwarnings
filterwarnings('ignore')# 警告を無視





df=pd.read_csv('./data/dataset/delaney-processed.csv')
df['mol'] = df['smiles'].apply(Chem.MolFromSmiles)
df





from cheminfo.descriptors import HashedMorgan

hm = HashedMorgan(256,2)
X = hm.fit_transform(df['mol'])
X


X.shape





y = df['measured log solubility in mols per litre']
y








X_train, X_test, Y_train, Y_test = train_test_split(X, 
                                                    y, 
                                                    test_size=.20,
                                                    random_state=42
                                                   )





model =  LinearRegression()
model.fit(X_train, Y_train)





#predicts the X_train
Y_pred_train = model.predict(X_train)

#predicts the X_test
Y_pred_test = model.predict(X_test)





#predicts the X_train
mse = mean_squared_error(Y_train, Y_pred_train)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))


#predicts the X_test
mse = mean_squared_error(Y_test, Y_pred_test)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))





#predicts the X_train
r2 = r2_score(Y_train, Y_pred_train)
print('決定係数 (R^2): {:.3f}'.format(r2))


#predicts the X_test
r2 = r2_score(Y_test, Y_pred_test)
print('決定係数 (R^2): {:.3f}'.format(r2))





#predicts the X_train
mae = mean_absolute_error(Y_train, Y_pred_train)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))


#predicts the X_test
mae = mean_absolute_error(Y_test, Y_pred_test)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))





#predicts the X_train
rmse = np.sqrt(mean_squared_error(Y_train, Y_pred_train))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))


#predicts the X_test
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred_test))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))





plt.figure(figsize=(6,6))

plt.scatter(x=Y_train, y=Y_pred_train, c="blue", alpha=1)
plt.scatter(x=Y_test, y=Y_pred_test, c="#619CFF", alpha=1)

plt.xlabel('Exp.', fontsize=13)
plt.ylabel('Predict', fontsize=13)
plt.xlim(-12,4)
plt.ylim(-12,4)
plt.grid()

plt.show()





model =  PLSRegression()
model.fit(X_train, Y_train)





#predicts the X_train
Y_pred_train = model.predict(X_train)

#predicts the X_test
Y_pred_test = model.predict(X_test)





#predicts the X_train
mse = mean_squared_error(Y_train, Y_pred_train)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))


#predicts the X_test
mse = mean_squared_error(Y_test, Y_pred_test)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))





#predicts the X_train
r2 = r2_score(Y_train, Y_pred_train)
print('決定係数 (R^2): {:.3f}'.format(r2))


#predicts the X_test
r2 = r2_score(Y_test, Y_pred_test)
print('決定係数 (R^2): {:.3f}'.format(r2))





#predicts the X_train
mae = mean_absolute_error(Y_train, Y_pred_train)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))


#predicts the X_test
mae = mean_absolute_error(Y_test, Y_pred_test)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))





#predicts the X_train
rmse = np.sqrt(mean_squared_error(Y_train, Y_pred_train))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))


#predicts the X_test
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred_test))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))





plt.figure(figsize=(6,6))

plt.scatter(x=Y_train, y=Y_pred_train, c="blue", alpha=1)
plt.scatter(x=Y_test, y=Y_pred_test, c="#619CFF", alpha=1)

plt.xlabel('Exp.', fontsize=13)
plt.ylabel('Predict', fontsize=13)
plt.xlim(-12,4)
plt.ylim(-12,4)
plt.grid()

plt.show()





model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, Y_train)





#predicts the X_train
Y_pred_train = model.predict(X_train)

#predicts the X_test
Y_pred_test = model.predict(X_test)





#predicts the X_train
mse = mean_squared_error(Y_train, Y_pred_train)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))


#predicts the X_test
mse = mean_squared_error(Y_test, Y_pred_test)
print('平均二乗誤差 (MSE): {:.3f}'.format(mse))





#predicts the X_train
r2 = r2_score(Y_train, Y_pred_train)
print('決定係数 (R^2): {:.3f}'.format(r2))


#predicts the X_test
r2 = r2_score(Y_test, Y_pred_test)
print('決定係数 (R^2): {:.3f}'.format(r2))





#predicts the X_train
mae = mean_absolute_error(Y_train, Y_pred_train)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))


#predicts the X_test
mae = mean_absolute_error(Y_test, Y_pred_test)
print('平均絶対誤差（MAE） : {:.3f}'.format(mae))





#predicts the X_train
rmse = np.sqrt(mean_squared_error(Y_train, Y_pred_train))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))


#predicts the X_test
rmse = np.sqrt(mean_squared_error(Y_test, Y_pred_test))
print('二乗平均平方誤差(RMSE) : {:.3f}'.format(rmse))





plt.figure(figsize=(6,6))

plt.scatter(x=Y_train, y=Y_pred_train, c="blue", alpha=1)
plt.scatter(x=Y_test, y=Y_pred_test, c="#619CFF", alpha=1)

plt.xlabel('Exp.', fontsize=13)
plt.ylabel('Predict', fontsize=13)
plt.xlim(-12,4)
plt.ylim(-12,4)
plt.grid()

plt.show()





from sklearn.model_selection import GridSearchCV
from sklearn import metrics


df_train, df_test = train_test_split(df, 
                                     test_size=.20, 
                                     random_state=42)


TARGET=['measured log solubility in mols per litre']
ytrain = df_train[TARGET]
ytrain


params={'n_components': np.arange(1,16)}
scores = np.zeros((18,3))
count = 0

for radius in range(1, 4):
    for n_bits in 2**np.arange(5, 11):
        model = GridSearchCV(PLSRegression(), params, cv=5)
        Xtrain = HashedMorgan(n_bits, radius).fit_transform(df_train['mol'])

        model.fit(Xtrain, ytrain)
        
        score_cv = model.best_score_
        scores[count,:] = np.array([radius, n_bits, score_cv])
        count+=1 





mpl.rcParams['figure.figsize'] = [12, 8]
mpl.rcParams['font.size'] = 20

fig,ax=plt.subplots()
im = ax.imshow(scores[:,-1].reshape(3,6).T)
fig.colorbar(im)

ax.set_xticks(range(3))
ax.set_yticks(range(6))
ax.set_xticklabels(range(1,4))
ax.set_yticklabels(map(int,scores[:6,1]))

plt.xlabel('radius')
plt.ylabel('number of but')
#plt.savefig('./results/10.3-optim-hashedmorgan-pls.jpg')

plt.show()





ix=scores[:,-1].argmax()
print('radius: {}, n_bits: {} R^2:{:.3f}'.format(*scores[ix,:]))





from cheminfo.descriptors import RDKitDescriptor

rdcalc = RDKitDescriptor()

X = rdcalc.fit_transform(df_train['mol'])
Xtrain = np.array(X.tolist())

X2 = rdcalc.transform(df_test['mol'])
Xtest = np.array(X2.tolist())


ytest = df_test[TARGET]


params = {'n_components': np.arange(1, 16)}
optim = GridSearchCV(PLSRegression(), params)


optim.fit(Xtrain, ytrain)





ycalc = optim.predict(Xtrain)
ypred = optim.predict(Xtest)





print('calc: %.3f'%metrics.r2_score(ytrain,ycalc))
print('cv: %.3f'%optim.best_score_)
print('pred: %.3f'%metrics.r2_score(ytest,ypred))








plt.figure(figsize=(6,6))

plt.plot(ytrain, ycalc, '.')
plt.plot(ytest, ypred, '^')
#plt.plot()

plt.axis('square')
plt.xlabel('Exp.')
plt.ylabel('Predict')

plt.xlim(-12,4)
plt.ylim(-12,4)
plt.grid()

#plt.savefig('./results/9.3-yyplot-rdkitpls.jpg')
plt.show()





from joblib import dump
dump(optim, './models/9.3_rdkit_pls.joblib')








toluene = Chem.MolFromSmiles('Cc1ccccc1')
hmfp = GetHashedMorganFingerprint(mol=toluene, radius=3, nBits=512)











hmfp.GetNonzeroElements()








from cheminfo.descriptors import HashedMorgan

hm = HashedMorgan()
X = hm.fit_transform(df['mol'])


X.shape


plt.hist(X.sum(axis=1), bins=100)

plt.xlabel('Freq')
plt.ylabel('Number of Samples')
plt.show()



